@article{Start2020,
mendeley-groups = {Thesis},
number = {777533},
pages = {1--163},
title = {{PROviding Computing solutions for ExaScale ChallengeS}},
year = {2020}
}
@article{Spreeuw2019,
author = {Spreeuw, Hanno and Madougou, Souley and Haren, Ronald Van and Weel, Berend and Belloum, Adam and Maassen, Jason},
doi = {10.1109/eScience.2019.00061},
file = {:D$\backslash$:/Master{\_}Study/Thesis/Master-thesis-project/Literature/Unlocking the LOFAR LTA.pdf:pdf},
isbn = {9781728124513},
mendeley-groups = {Thesis},
pages = {467--470},
title = {{Unlocking the LOFAR LTA}},
year = {2019}
}
@article{Kazemi2011,
abstract = {The aim of the new generation of radio synthesis arrays such as LOw Frequency ARray (LOFAR) and Square Kilometre Array (SKA) is to achieve much higher sensitivity, resolution and frequency coverage than what is available now, especially at low frequencies. To accomplish this goal, the accuracy of the calibration techniques used is of considerable importance. Moreover, since these telescopes produce huge amounts of data, speed of convergence of calibration is a major bottleneck. The errors in calibration are due to system noise (sky and instrumental) as well as the estimation errors introduced by the calibration technique itself, which we call 'solver noise'. We define solver noise as the 'distance' between the optimal solution (the true value of the unknowns, uncorrupted by the system noise) and the solution obtained by calibration. We present the Space Alternating Generalized Expectation Maximization (SAGE) calibration technique, which is a modification of the Expectation Maximization algorithm, and compare its performance with the traditional least squares calibration based on the level of solver noise introduced by each technique. For this purpose, we develop statistical methods that use the calibrated solutions to estimate the level of solver noise. The SAGE calibration algorithm yields very promising results in terms of both accuracy and speed of convergence. The comparison approaches that we adopt introduce a new framework for assessing the performance of different calibration schemes. {\textcopyright} 2011 The Authors Monthly Notices of the Royal Astronomical Society {\textcopyright} 2011 RAS.},
archivePrefix = {arXiv},
arxivId = {1012.1722},
author = {Kazemi, S. and Yatawatta, S. and Zaroubi, S. and Lampropoulos, P. and de Bruyn, A. G. and Koopmans, L. V.E. and Noordam, J.},
doi = {10.1111/j.1365-2966.2011.18506.x},
eprint = {1012.1722},
file = {:D$\backslash$:/Master{\_}Study/Thesis/Master-thesis-project/Literature/mnras0414{\_}1656.pdf:pdf},
issn = {00358711},
journal = {Monthly Notices of the Royal Astronomical Society},
keywords = {Methods: numerical,Methods: statistical,Techniques: interferometric},
mendeley-groups = {Thesis},
number = {2},
pages = {1656--1666},
title = {{Radio interferometric calibration using the SAGE algorithm}},
volume = {414},
year = {2011}
}
@article{Lorido-Botran2014,
abstract = {Cloud computing environments allow customers to dynamically scale their applications. The key problem is how to lease the right amount of resources, on a pay-as-you-go basis. Application re-dimensioning can be implemented effortlessly, adapting the resources assigned to the application to the incoming user demand. However, the identification of the right amount of resources to lease in order to meet the required Service Level Agreement, while keeping the overall cost low, is not an easy task. Many techniques have been proposed for automating application scaling. We propose a classification of these techniques into five main categories: static threshold-based rules, control theory, reinforcement learning, queuing theory and time series analysis. Then we use this classification to carry out a literature review of proposals for auto-scaling in the cloud.},
author = {Lorido-Botran, Tania and Miguel-Alonso, Jose and Lozano, Jose A.},
doi = {10.1007/s10723-014-9314-7},
file = {:D$\backslash$:/Master{\_}Study/Thesis/Master-thesis-project/Literature/Auto-scaling Techniques for Elastic Applications in Cloud Environments.pdf:pdf},
issn = {15707873},
journal = {Journal of Grid Computing},
keywords = {Auto-scaling,Cloud computing,Scalable applications,Service level agreement},
mendeley-groups = {Thesis},
number = {4},
pages = {559--592},
title = {{A Review of Auto-scaling Techniques for Elastic Applications in Cloud Environments}},
volume = {12},
year = {2014}
}
@article{Kang2013,
abstract = {The advent of Science Clouds enables scientists to facilitate large-scale scientific computational experiments over cloud environment besides specialized supercomputers in diverse science domains. Cloud computing service elicits efficiency on on-demand resource usage and timely execution at any given time depending on experimental requirements. Hybrid clouds, composing of private and public clouds, even extend research opportunities on resource selection for further complicated experiments but increase the needs of dynamic resource management to maximize its utilization. At existing public cloud providers for commercial use, rule-based and schedule-based mechanisms have been tried for automatic resource allocation to provide resources for processing dynamic workload of modern applications. However, most of the auto-scaling methods just simply support performance metric such as CPU utilization but rarely are aware of Service Level Agreements (SLA) including execution deadline or cost. In this paper, we propose an auto-scaling method that automatically allocates resources depending on variable resource requirements in hybrid clouds satisfying a user's requirements on SLA. We present experimental results which show that the proposed auto-scaling can minimize SLA violations and acceptable cost if needed. {\textcopyright} 2013 IEICE.},
author = {Kang, Hyejeong and Koh, Jung In and Kim, Yoonhee and Hahm, Jaegyoon},
file = {:D$\backslash$:/Master{\_}Study/Thesis/Master-thesis-project/Literature/A SLA driven VM Auto-Scaling Method in Hybrid Cloud Environment .pdf:pdf},
isbn = {9784885522796},
journal = {15th Asia-Pacific Network Operations and Management Symposium: "Integrated Management of Network Virtualization", APNOMS 2013},
keywords = {SLA,auto-scaling,hybrid cloud computing,multi-policies},
mendeley-groups = {Thesis},
title = {{A SLA driven VM auto-scaling method in hybrid cloud environment}},
year = {2013}
}
@article{Mao2011,
abstract = {A goal in cloud computing is to allocate (and thus pay for) only those cloud resources that are truly needed. To date, cloud practitioners have pursued schedule-based (e.g., time-of-day) and rule-based mechanisms to attempt to automate this matching between computing requirements and computing resources. However, most of these "auto-scaling" mechanisms only support simple resource utilization indicators and do not specifically consider both user performance requirements and budget concerns. In this paper, we present an approach whereby the basic computing elements are virtual machines (VMs) of various sizes/costs, jobs are specified as workflows, users specify performance requirements by assigning (soft) deadlines to jobs, and the goal is to ensure all jobs are finished within their deadlines at minimum financial cost. We accomplish our goal by dynamically allocating/deallocating VMs and scheduling tasks on the most cost-efficient instances. We evaluate our approach in four representative cloud workload patterns and show cost savings from 9.8{\%} to 40.4{\%} compared to other approaches. Copyright 2011 ACM.},
author = {Mao, Ming and Humphrey, Marty},
doi = {10.1145/2063384.2063449},
file = {:D$\backslash$:/Master{\_}Study/Thesis/Master-thesis-project/Literature/Auto-Scaling to Minimize Cost and Meet Application Deadlines in Cloud Workflows.pdf:pdf},
isbn = {9781450307710},
journal = {Proceedings of 2011 SC - International Conference for High Performance Computing, Networking, Storage and Analysis},
keywords = {Auto-scaling,Cloud computing,Cost-minimization},
mendeley-groups = {Thesis},
pages = {1--12},
publisher = {IEEE},
title = {{Auto-scaling to minimize cost and meet application deadlines in cloud workflows}},
year = {2011}
}
